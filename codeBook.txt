#run_analysis.R Code Book - Getting and Cleaning Data Course Project

The main train and test data files contain the full set of measures of the subjects and activity for 
the Samsung phone accelrometer and gyroscope human activity recognition project referenced in full detail below.
In summary, 30 subjects were given Samsung phones outfitted with accelerometers and gyroscopes that took various
measurements while they performed 6 activities of walking, sitting, walking upstairs, walking downstairs and laying down.
The details of the experiment are detailed thoroughly here, 
http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones
and in the readme.txt file included in the data files.  The contents of this file have been included at the bottom of 
this code book, which describes each step of the work done with the downloaded data in the run_analysis.R script.

The files can be downloaded from: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip 
and placed in the local R working directory.  Only the x_test, x_train, y_test, y_train, features, activity_labels,
subject_train and subject_test files were loaded into R.  The files contained in the Inertial folders were determined
to be surplus to the requirements of the assignment.

The dplyr package was required for data manipulation througout the script.
1) Load lookup values for activities from activity_labels.txt          

2) The column names in activity_labels are renamed to activity and activity_labels. 

3) The features variables are loaded in from Features.txt.  These are equivalent to the 561 columns in both 
x_train and x_test and will be joined to those tables to provide descriptive labels.

4) The full set of oberservations for the train and test data are loaded into separate tables for now with 
missing values set to a string value of NA.

5) The column names in both train and test are renamed using the row values of the Features table as they are 
positioned from 1-561 and are equivalent to the column positions train and test. Parameters are set in the 
make.names function to enforce unique names and underscoring.

6) The test subjects are loaded in from subject_train.txt and subject_test.txt.  There are 30 subjects in total.
The column in this table is renamed to 'subject' and appended using cbind to the subject_train and subject_test data.

7) The subjects are then appended to the main train and test tables also using cbind.

8) The activities are then loaded and joined using the full_join function to the main train and test tables after 
the column name is renamed to 'activity'.  

9) The train and test table rows are then combined using rbind to create a combined table of all of the observations
for both train and test data.  This data now has descriptively named columns for the apropriate subject, activity code 
and label.

10) An index is now created using the grep function looking for the positions of columns that contain measures for mean 
or standrard deviation.  The positions for the subject, activity and activity label columns are also returned in order 
to maintain them in the final table.

11) The columns returned are then used to subset the train/test table to include only the mean, std, subject and 
activity columns.

12) The mean for each grouping of activity and subject is then calculated.  This yields a total of 180 summary rows, 
for 30 subjects and 6 activities each.  There are 82 columns and 180 rows in the resulting tidy data.

13) A tidy data text file is then written out using the write.table function with row.names=FALSE in order to remove an 
additional blank column being inserted into the data.

14) This file can be read back into R using read.table with header=TRUE yielding a table of 180 rows and 82 
columns.

Below is the original README.txt that was downloaded with the data.

==================================================================
Human Activity Recognition Using Smartphones Dataset
Version 1.0
==================================================================
Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto.
Smartlab - Non Linear Complex Systems Laboratory
DITEN - Universit√† degli Studi di Genova.
Via Opera Pia 11A, I-16145, Genoa, Italy.
activityrecognition@smartlab.ws
www.smartlab.ws
==================================================================

The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. 

The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details. 

For each record it is provided:
======================================

- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.
- Triaxial Angular velocity from the gyroscope. 
- A 561-feature vector with time and frequency domain variables. 
- Its activity label. 
- An identifier of the subject who carried out the experiment.

The dataset includes the following files:
=========================================

- 'README.txt'

- 'features_info.txt': Shows information about the variables used on the feature vector.

- 'features.txt': List of all features.

- 'activity_labels.txt': Links the class labels with their activity name.

- 'train/X_train.txt': Training set.

- 'train/y_train.txt': Training labels.

- 'test/X_test.txt': Test set.

- 'test/y_test.txt': Test labels.

The following files are available for the train and test data. Their descriptions are equivalent. 

- 'train/subject_train.txt': Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30. 

- 'train/Inertial Signals/total_acc_x_train.txt': The acceleration signal from the smartphone accelerometer X axis in standard gravity units 'g'. Every row shows a 128 element vector. The same description applies for the 'total_acc_x_train.txt' and 'total_acc_z_train.txt' files for the Y and Z axis. 

- 'train/Inertial Signals/body_acc_x_train.txt': The body acceleration signal obtained by subtracting the gravity from the total acceleration. 

- 'train/Inertial Signals/body_gyro_x_train.txt': The angular velocity vector measured by the gyroscope for each window sample. The units are radians/second. 

Notes: 
======
- Features are normalized and bounded within [-1,1].
- Each feature vector is a row on the text file.

For more information about this dataset contact: activityrecognition@smartlab.ws

License:
========
Use of this dataset in publications must be acknowledged by referencing the following publication [1] 

[1] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012

This dataset is distributed AS-IS and no responsibility implied or explicit can be addressed to the authors or their institutions for its use or misuse. Any commercial use is prohibited.

Jorge L. Reyes-Ortiz, Alessandro Ghio, Luca Oneto, Davide Anguita. November 2012.
